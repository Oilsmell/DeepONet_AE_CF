DANN 을 사용한 Autoencoder
A, B 건강데이터를 각각 분리하여 Norminalization진행
A, B에 각각 라벨링
오토인코더에 DANN을 사용, 오토인코더 병목에 MLP(Multi-Layer Perceptron)추가
인코더에서 Latent Vector z생성, MLP Classifier에서 z가 A인지 B인지 판별
Classifier 과정 전에 Gradient Reversal Layer를 통해서 Adverarial Domain 진행. 
GRL 파라미터 Adversarial Loss의 가중치를 조절해서 A, B의 데이터가 너무 겹치지 않게 조절.
t-SNE로 Latent Vector에서 A, B가 얼마나 겹쳤는지 확인.
Accuracy가 50%이면 완전 겹침 100%이면 완전 분리. 즉 60-70%의 Accuracy를 달성하도록 함.
이제 생성된 오토인코더 출력을 DeepONet으로 넣고 학습.
DI는 정규화 하여서 입력 input_di = 0.1 + (real_di - min_di) / (max_di - min_di) * 0.9 # [0.1, 1.0] Scaling 즉 0.1에서 1 사이의 값으로 보정
입력에는 오토인코더로 변환된 건강 데이터, DI가 Branch Net으로
시공간이 FFE를 통해 Trunk Net으로
Target Value에는 정규화된 손상데이터 - 건강데이터 즉 잔차가 설정됨.

데이터 검증에서는, 건강 데이터와 실제 손상 데이터로 DI 구한다음, DI는 정규화 하여서 입력 input_di = 0.1 + (real_di - min_di) / (max_di - min_di) * 0.9 # [0.1, 1.0] Scaling 즉 0.1에서 1 사이의 값으로 보정
출력은 정규화된 A의 건강데이터 + 출력된 예측 잔차
그리고 나서 더해진 데이터를 스케일 인버스를함.
그리고 건강데이터 원본과 인버스된 데이터를 Kurtosis로 DI를 구함.
